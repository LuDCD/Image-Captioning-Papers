# Image-Captioning-Papers

[1] O. Vinyals, A. Toshev, S. Bengio and D. Erhan, "**Show and tell: A neural image caption generator**," CVPR 2015.  [[pdf](https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Vinyals_Show_and_Tell_2015_CVPR_paper.pdf)] [[code](https://github.com/tensorflow/models/tree/master/research/im2txt)]
[2] H. Fang et al., "**From captions to visual concepts and back**," CVPR 2015.[[pdf]](https://arxiv.org/pdf/1411.4952v3.pdf)[code]
[3] X. Jia, E. Gavves, B. Fernando and T. Tuytelaars, "**Guiding the Long-Short Term Memory Model for Image Caption Generation**" ICCV  2015.[\[pdf\]](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7410634)[code]
[4] Zhou, Luowei, et al. "**Watch what you just said: Image captioning with text-conditional attention**." Proceedings of the on Thematic Workshops of ACM Multimedia 2017. ACM, 2017.[\[pdf\]](https://arxiv.org/pdf/1606.04621v3.pdf)[code]
[5] Q. Wu, C. Shen, L. Liu, A. Dick and A. v. d. Hengel, "**What Value Do Explicit High Level Concepts Have in Vision to Language Problems?**" CVPR 2016.[\[pdf\]](https://arxiv.org/pdf/1506.01144.pdf)[code]
[6] Yao, Ting, et al. "**Boosting image captioning with attributes.**" Proceedings of the IEEE International Conference on Computer Vision. 2017.[\[pdf\]](http://openaccess.thecvf.com/content_ICCV_2017/papers/Yao_Boosting_Image_Captioning_ICCV_2017_paper.pdf)[code]
[7] Lu, Jiasen, et al. "**Knowing when to look: Adaptive attention via a visual sentinel for image captioning.**" Proceedings of the IEEE conference on computer vision and pattern recognition. 2017.[\[pdf\]](http://openaccess.thecvf.com/content_cvpr_2017/papers/Lu_Knowing_When_to_CVPR_2017_paper.pdf)[code]
[8] Tanti, Marc, Albert Gatt, and Kenneth P. Camilleri. "**Transfer learning from language models to image caption generators: Better models may not transfer better.**" arXiv preprint arXiv:1901.01216 (2019).[\[pdf\]](https://arxiv.org/pdf/1901.01216.pdf)[code]


----
end



